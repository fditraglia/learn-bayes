---
title: "Hierarchical Models - BDA Chapter 5"
format: 
  html:
    embed-resources: true
---

## What is this?
- A lightning introduction to Hierarchical Bayesian Models
- Draws from Chapter 5 of Gelman et al. (2013) "Bayesian Data Analysis" and Chapter 17 of Lambert (2018) "A Student's Guide to Bayesian Statistics" along with [this example](https://mc-stan.org/users/documentation/case-studies/pool-binary-trials.html)
- See also McElreath (2020) "Statistical Rethinking" 

## Rats Dataset

- Example based on Gelman et al. (2013) "Bayesian Data Analysis" Chapter 5.
- 71 experiments on rats, each with a different number of subjects. 
- Each experiment has a control group and a treatment group.
- We have data from the *control group* for each experiment.
- Observe number of rats in each experiment and number that develop a tumor.
- Goal is to estimate the incidence of tumors in rats from 71 experiments.
- Could be any binary outcome, e.g. success/failure, yes/no, etc.

```{r}
#| message: false
#| warning: false
library(tidyverse)
rats_url <- "http://www.stat.columbia.edu/~gelman/book/data/rats.asc"
rats <- read.table(rats_url, header = TRUE, skip = 2) |> 
  as_tibble() 

rats
```

## Consider the 71st experiment
How should we estimate the incidence of tumors for this experiment?
```{r}
rats |> 
  slice_tail(n = 1)
```

### Textbook Frequentist Approach
$$
\hat{\theta}_{71} = \frac{y_{71}}{N_{71}} = \frac{4}{14} \approx 0.29, \quad \text{SE}(\hat{\theta}_{71}) = \sqrt{\frac{\hat{\theta}_{71}(1 - \hat{\theta}_{71})}{N_{71}}} \approx 0.12
$$

- Approximate 95\% confidence interval is $0.29 \pm 2 \times 0.12$ or $[0.05, 0.53]$.
- Very small sample size; Frequentist asymptotics [can be unreliable]()
- Completely ignores information from the other 70 experiments!

## Quick Review of Beta$(\alpha, \beta)$ Distribution 
- Continuous RV;  support set $[0, 1]$; wide range of shapes
- Parameters: $\alpha, \beta > 0$
- $X \sim \text{Beta}(\alpha, \beta) \iff f(x| \alpha, \beta) \propto x^{\alpha - 1}(1 - x)^{\beta - 1}$ 
- $\text{Uniform}(0, 1)$ is a special case: $\text{Beta}(1, 1)$
$$
\begin{align*}
\mathbb{E}[X] &= \frac{\alpha}{\alpha + \beta}\\
\text{Mode}(X) &= \frac{\alpha - 1}{\alpha + \beta - 2} \quad \text{for } \alpha, \beta > 1\\
\text{Var}(X) &= \frac{\alpha\beta}{(\alpha + \beta)^2(\alpha + \beta + 1)}
\end{align*}
$$

```{r}
plot_beta_examples <- function(alpha, beta, legend_pos = 'topright') {
  x <- seq(from = 0.005, to = 0.995, length.out = 500)
  fx <- map2(alpha, beta, \(a, b) dbeta(x, a, b)) |> 
    reduce(cbind) 
  matplot(x, fx, type = 'l', lwd = 3, xlab = 'x', ylab = 'f(x)')
  my_legend <- map2_chr(alpha, beta, \(x, y) paste0('Beta(', x, ', ', y, ')'))
  legend(legend_pos, legend = my_legend, lty = 1:4, lwd = 2, col = 1:4)
}

plot_beta_examples(alpha = c(4, 2, 1, 0.5), 
                    beta = c(4, 2, 1, 0.5))

plot_beta_examples(alpha = c(0.5, 1, 2), 
                    beta = c(1,   2, 8))

plot_beta_examples(alpha = c(1,   2, 8),
                    beta = c(0.5, 1, 2), 'topleft')
```



## Textbook Bayesian Inference for a Proportion $\theta$
- **Likelihood**: $y|\theta \sim \text{Binomial}(N, \theta)$ 
- **Prior**: $\theta \sim \text{Beta}(\alpha, \beta)$
 

$$
\begin{aligned}
\text{Posterior} &\propto \text{Likelihood} \times \text{Prior} \\
f(\theta | y) &\propto f(y | \theta) \times f(\theta) \\
&\propto \left[\theta^y (1 - \theta)^{N - y}\right] \times \left[\theta^{\alpha - 1} (1 - \theta)^{\beta - 1}\right] \\
&\propto \theta^{y + \alpha - 1} (1 - \theta)^{N - y + \beta- 1}
\end{aligned}
$$

- **Posterior**: $\theta | y \sim \text{Beta}(y + \alpha, N - y + \beta)$.
- **Posterior Mean**: $\frac{y + \alpha}{N + \alpha + \beta}$

## Experiment \# 71
- $N_{71} = 14$; $y_{71} = 4$
- **Posterior**: $\theta \sim \text{Beta}(4 + \alpha, 10 + \beta)$,  **Posterior Mean**: $\hat{\theta}_{71} = \frac{4 + \alpha}{14 + \alpha + \beta}$
- I don't know much about rats and tumors so I'm not sure what $\alpha$ and $\beta$ to use...


```{r}
library(HDInterval)

plot_prior_to_posterior <- function(y, N, alpha, beta) {
  a <- y + alpha
  b <- N - y + beta
  
  theta <- seq(from = 0.005, to = 0.995, length.out = 500)
  prior <- dbeta(theta, alpha, beta)
  posterior <- dbeta(theta, a, b) 
  
  matplot(theta, cbind(prior, posterior), type = 'l', lwd = 2, 
          col = c('blue', 'red'), xlab = expression(theta), ylab = 'Density')
  legend('topright', legend = c('Prior', 'Posterior'), lty = 1, lwd = 2, 
         col = c('blue', 'red'))
  
  posterior_mean <- a / (a + b) 
  hdi_95 <- hdi(qbeta, shape1 = a, shape2 = b, credMass = 0.95)
  mytext <- paste0('Posterior Mean: ', round(posterior_mean, 2), 
         '\n95% HPDI: [', round(hdi_95[1], 2), ', ', round(hdi_95[2], 2), ']')
  text(0.5, 0.5 * max(max(prior), max(posterior)), mytext, adj = 0, 
       cex = 1.2, col = 'black')
}

plot_prior_to_posterior(y = 4, N = 14, alpha = 1, beta = 1)
plot_prior_to_posterior(y = 4, N = 14, alpha = 1, beta = 2)
plot_prior_to_posterior(y = 4, N = 14, alpha = 2, beta = 8)
plot_prior_to_posterior(y = 4, N = 14, alpha = 0.5, beta = 1)
```

## How can we do better?
- Results aren't too sensitive to reasonable choices of $\alpha$ and $\beta$.
- But we're still quite uncertain about the true value of $\theta_{71}$!
- **Idea**: use data from other 70 experiments to inform our prior for the 71st.


## First Idea: Pooling Data

- Suppose that the *true* incidence of tumors in rats is the same across all experiments. 
- Then it would make sense to *pool* the data to estimate $\theta_{71}$
- One way to think of this: pool the data from experiments 1-70 to "estimate" a prior for experiment 71.
- Then proceed as before. 
- Equivalent way to think about it: pool all 71 experiments to learn about the true incidence of tumors in rats.

## A Pooled Prior from Experiments 1-70
```{r}
#| echo: false
y_1_to_70 <- rats |> 
  slice_head(n = -1) |> 
  pull(y) |> 
  sum()

N_1_to_70 <- rats |> 
  slice_head(n = -1) |> 
  pull(N) |> 
  sum()
```

- **Prior**: $\theta \sim \text{Beta}(\alpha, \beta)$
- **Likelihood**: $y_{j} | \theta \sim \text{indep. Binomial}(N_j, \theta)$
- **Equivalently**: $\sum y_j |\theta \sim \text{Binomial}\left(\sum N_j, \theta\right)$
- **Posterior**: $\theta | \sum y_j \sim \text{Beta}\left(\sum y_j + \alpha, \sum N_j - \sum y_j + \beta\right)$
- $\sum y_j=$ `r y_1_to_70` and $N_j=$ `r N_1_to_70` for experiments 1-70, so $\alpha$ and $\beta$ will barely matter
- For simplicity: $\alpha = \beta = 1 \implies \theta | (y_1, \dots y_{70}) \sim \text{Beta}(264, 1463)$

## Inference for Experiment 71 using Pooled Prior

```{r}
plot_prior_to_posterior(y = 4, N = 14, alpha = 264, beta = 1463)
```

- Very precise inference for $\theta_{71}$
- But the data from Experiment 71 is basically ignored!
- Swamped by the prior constructed from experiments 1-70.
- Feature or bug?
  - Feature if we *really believe* same $\theta$ for all experiments
  - Bug if we think $\theta$ might vary across experiments
  
  
## Better Idea: Hierarchical Model

- Rather than a single $\theta$ for all experiments, allow a different one $\theta_j$ for each.
- Treat $(\theta_1, \theta_2, \dots, \theta_{70})$ as draws from a *common distribution* 
$$
\theta_j | \alpha, \beta \sim \text{independent Beta}(\alpha, \beta)\quad \text{for } j = 1, 2, \dots, 71
$$
- Conditional on $(\alpha, \beta)$ the parameters $\theta_1, \dots, \theta_{71}$ are independent
- Known $(\alpha, \beta) \implies$ no extra information about $\theta_{71}$ from other experiments 
- Unconditionally, the parameters $\theta_1, \dots, \theta_{71}$ are *dependent*
- Unknown $(\alpha, \beta) \implies$ other experiments *indirectly* inform us about $\theta_{71}$ through the info they provide about $(\alpha, \beta)$.

## Exchangeability

- **Recall**: unconditionally, the parameters $\theta_1, \dots, \theta_{71}$ are *dependent*
- But because they come from a *common distribution* they are *identically distributed*.
- In fact we can say more: they are **exchangeable**: the joint distribution of $(\theta_1, \dots, \theta_{71})$ is invariant to permutations of the indices (c.f. *strong stationarity* in time series)

## What does exchangeability mean in practice?

- A kind of "symmetry" between the experiments
- They're different, but we don't know *how* they're different
- E.g.\ the experimental conditions may vary but we *don't know* for example, that experiments 1-10 were performed in Lab A and experiments 11-28 in Lab B.
- If we know more about the experiments, exchangeability would be violated.
- But in that case we could use the extra information to build an *even better model* in which exchangeability holds after we condition on what we know.
- This is a bit subtle, but is discussed in some detail in Meager (2019).
- Another example: suppose we have 71 *polls* carried out over time. If there are trends in public opinion, the polls are not exchangeable.
- But after estimating a *trend* in public opinion, the *residuals* from the trend might be exchangeable.


## The Challenge: $\theta_1, \dots, \theta_{71}$ are *unobserved*

- **Unobserved**: $\theta_j | \alpha, \beta \sim \text{independent Beta}(\alpha, \beta)$
- **Observed**: $y_j | \theta_j \sim \text{independent Binomial}(N_j, \theta_j)$
- We want to infer $\theta_{71}$, but we don't know $\alpha$ and $\beta$.
- Other experiments contain information about $\alpha$ and $\beta$ but don't know $\theta_1, \dots, \theta_{70}$ either! 
- Somehow we need to *infer* $(\alpha, \beta)$ from the observed data and then use them to infer $\theta_{71}$.
- Start with a simple and intuitive idea that is *slightly wrong* but gets the idea across.
- After that I'll show you how to do things the right way!

## A Crude Approximation

- **Unobserved**: $\theta_j | \alpha, \beta \sim \text{independent Beta}(\alpha, \beta)$
- **Observed**: $y_j | \theta_j \sim \text{independent Binomial}(N_j, \theta_j)$
- **Idea**: treat *estimates* $\hat{\theta}_j$ as the *true* parameters $\theta_j$; use them to estimate $(\alpha, \beta)$.
- In particular: set $\hat{\theta}_j = \frac{y_j}{N_j}$ and use the method of moments to estimate $(\alpha, \beta)$.

## Method of Moments Estimation of $(\alpha, \beta)$

- Suppose we observed $\theta_1, \dots, \theta_{70} \sim \text{iid Beta}(\alpha, \beta)$.
- We know how the mean and variance of this distribution relate to $(\alpha, \beta)$
$$
\begin{align*}
\mathbb{E}[\theta_j] &= \frac{\alpha}{\alpha + \beta}\\
\text{Var}[\theta_j] &= \frac{\alpha\beta}{(\alpha + \beta)^2(\alpha + \beta + 1)}
\end{align*}
$$
- Solving for $\alpha$ and $\beta$ gives
$$
\begin{align*}
\alpha &= \mathbb{E}[\theta_j] \times \left(\frac{\mathbb{E}[\theta_j] \times (1 - \mathbb{E}[\theta_j])}{\text{Var}[\theta_j]} - 1\right)\\
\beta &= (1 - \mathbb{E}[\theta_j]) \times \left(\frac{\mathbb{E}[\theta_j] \times (1 - \mathbb{E}[\theta_j])}{\text{Var}[\theta_j]} - 1\right)
\end{align*}
$$
- Replace $\mathbb{E}[\theta_j]$ and $\text{Var}[\theta_j]$ with sample mean/variance $\theta_j$ to yield estimates $(\hat{\alpha}, \hat{\beta})$.
- Since $\theta_j$ unobserved, replace with $\hat{\theta}_j = \frac{y_j}{N_j}$.

```{r}
# Estimates of theta for experiments 1-70
theta_hat <- rats |> 
  slice_head(n = -1) |> 
  mutate(p = y / N) |> 
  pull(p)

# Histogram of estimates
hist(theta_hat, main = 'Estimates from Experiments 1-70', 
     xlab = expression(hat(theta)), ylab = 'Density', 
     col = 'lightblue', freq = TRUE)
rug(theta_hat)

# Method of moments estimates of alpha and beta based on experiments 1-70
theta_mean <- mean(theta_hat)
theta_var <- var(theta_hat)
alpha_hat <- theta_mean * (theta_mean * (1 - theta_mean) / theta_var - 1)
beta_hat <- (1 - theta_mean) * (theta_mean * (1 - theta_mean) / theta_var - 1)
c(alpha = alpha_hat, beta = beta_hat)


# Bayesian Posterior for theta_71 using alpha_hat and beta_hat
plot_prior_to_posterior(y = 4, N = 14, alpha = alpha_hat, beta = beta_hat)
title(main = 'Prior from Experiments 1-70: Exchangeable Thetas')

# Contrast with "vague" prior: alpha = beta = 1
plot_prior_to_posterior(y = 4, N = 14, alpha = 1, beta = 1) 
title(main = 'Beta(1, 1) Prior')

# Contrast with full pooling
plot_prior_to_posterior(y = 4, N = 14, alpha = 264, beta = 1463)
title(main = 'Prior from Experiments 1-70: Same Theta')
```

## Lessons from the Crude Approximation
- "No Pooling" prior: $\text{Beta}(1, 1)$ 
  - Gives 71st experiment **too much weight** when estimating $\theta_{71}$
  - Completely ignores the other 70 experiments!
  - High variance; tiny bias 
- "Full Pooling" prior: same $\theta$ for all experiments 
  - Gives 71st experiment **too little weight** when estimating $\theta_{71}$
  - Almost completely ignores data from 71st experiment!
  - Tiny variance; large bias
- "Partial Pooling" prior: assumes $\theta_j|(\alpha, \beta) \sim \text{indep Beta}(\alpha, \beta)$ 
  - **strikes a balance** between the full and partial pooling
  - Uses data from all 71 experiments to estimate $\theta_{71}$
  - Low variance; low bias
  
  
## Problems with the Crude Approximation

- Ignores the fact that $\theta_j$ are *estimates* rather than true parameters.
- As such, *understates* our true uncertainty about $(\alpha, \beta)$.
- Method of moments assums $\hat{\theta}_j$ are draws from a Beta distribution but they're not! 
    - (E.g. several are exactly zero)
- Ignores uncertainty in estimates of $(\alpha, \beta)$ as well: just plugs in estimates
- What if we wanted to estimate *each* of the $\theta_j$ simultaneously? 
    - Shouldn't re-use the same data twice
    - Need to re-estimate $(\alpha, \beta)$ for each $\theta_j$, data from experiments *besides* $j$.

## Solution: Mixture Distribution for $\theta_j$

### Conditional Joint Distribution 

$$
f(\theta_1, \dots, \theta_{71} | \alpha, \beta) = f(\theta_1 | \alpha, \beta) \times \dots \times f(\theta_{71} | \alpha, \beta) = \prod_{j = 1}^{J} f(\theta_j | \alpha, \beta)
$$

### Unconditional Joint Distribution (Law of Total Prob)

$$
\begin{aligned}
f(\theta_1, \dots, \theta_{71}) &= \iint_{A\mathbin{\times} B} f(\theta_1, \dots, \theta_{71} | \alpha, \beta)\, f(\alpha, \beta)\, \mathrm{d}\alpha \, \mathrm{d}\beta\\
&= \iint_{A\mathbin{\times} B} \left[\prod_{j = 1}^{J} f(\theta_j | \alpha, \beta) \right]f(\alpha, \beta)\, \mathrm{d}\alpha \, \mathrm{d}\beta 
\end{aligned}
$$


## Full Hierarchical Bayesian Model

$$
\begin{aligned}
\text{Likelihood:}  &  & y_j | \theta_j &\sim \text{Binomial}(N_j, \theta_j) &\quad \text{ (indep.) }\\
\text{Conditional Prior:} & & \theta_j | \alpha, \beta &\sim \text{Beta}(\alpha, \beta) &\quad \text{ (indep.) }\\
\text{Hyperprior:} & & (\alpha, \beta) &\sim f(\alpha, \beta)
\end{aligned}
$$

- Hierarchical Prior for $\theta_j$ has two ingredients: 
    1. Beta prior *given* $(\alpha, \beta)$
    2. Hyperprior for $(\alpha, \beta)$
- $y_j$ contains information about $\theta_k$ through $(\alpha, \beta)$
- Refinements to crude approximation:
    - Uncertainty in $(\alpha, \beta)$
    - Uncertainty in $\theta_j$ due to finite sample size



## A Hyperprior for $(\alpha, \beta)$

- Hard to interpret parameters of Beta distribution directly.
- Instead put priors on these *transformed parameters*: 
$$
\phi = \frac{\alpha}{\alpha + \beta}, \quad \kappa = \alpha + \beta, \quad
$$
- $\phi$ is the *mean* of the Beta distribution
- $\kappa$ is the "number of prior observations"
  - Beta-Binomial Posterior Mean: $(y + \alpha)/(N + \alpha + \beta)$
- Higher $\kappa$ for fixed $\phi$ means *lower variance*
  - Beta Variance: $\phi(1 - \phi)/(\kappa + 1)$
- Easier to think about $(\phi,\kappa)$ than $(\alpha, \beta)$.
- Inverse: $\alpha = \kappa \phi, \quad \beta = \kappa(1 - \phi)$

## The Full Model 
$$
\begin{aligned}
\text{Likelihood:}  &  & y_j | \theta_j &\sim \text{Binomial}(N_j, \theta_j) &\quad \text{ (indep.) }\\
\text{Conditional Prior:} & & \theta_j | \alpha, \beta &\sim \text{Beta}(\alpha, \beta) &\quad \text{ (indep.) }\\
\text{Hyperprior:} & & \alpha = \kappa \phi, & \quad \beta = \kappa(1 - \phi) &  \\
 & & \phi &\sim \text{Uniform}(0, 1) & \quad (\phi, \kappa \text{ indep.}) \\
 & & \kappa &\sim \text{Pareto}(1, 1.5) & 
\end{aligned}
$$

## What is a Pareto Distribution?
$$
X \sim \text{Pareto}(x_m, \gamma) \iff f(x) = \frac{\gamma x_m^\gamma}{x^{\gamma + 1}}, \quad x \geq x_m, \quad\gamma > 0 
$$

- Heavy-tailed distribution; often used for modeling "extreme" events
- $x_m$ is the *minimum* value of $X$
- $\gamma$ is the *shape* parameter; **smaller** $\gamma$ means heavier tail
- Finite mean if $\gamma > 1$, finite variance if $\gamma > 2$

```{r}
# Plot of Pareto(1, 1.5) density
x <- seq(from = 0, to = 10, length.out = 500)
xm <- 1
gamma <- 1.5
fx <- (x >= xm) * (gamma * xm^gamma) / x^(gamma + 1) 
plot(x, fx, type = 'l', lwd = 2, xlab = 'x', ylab = 'Density', 
     main = 'Pareto(1, 1.5) Density')
```


## Simulating the Model *Forwards*

Using the *parameters* to draw random *data*:

1. Draw $\phi$ from $\text{Uniform}(0, 1)$ and $\kappa$ from $\text{Pareto}(1, 1.5)$
2. Compute $\alpha = \kappa \phi$ and $\beta = \kappa(1 - \phi)$
3. For each $j = 1, \dots, 71$:
    - Draw $\theta_j$ from $\text{Beta}(\alpha, \beta)$
    - Draw $y_j$ from $\text{Binomial}(N_j, \theta_j)$
    
**Same values of $(\alpha,\beta)$ are used for all $\theta_j$ and this is crucial**


## Monte Carlo Inference: Simulating **Backwards** 

Using the *data* to draw random *parameters*:

- Simulate draws from posteriors of $(\alpha, \beta)$ and $\{\theta_j\}_{j=1}^J$ given observed $\{(N_j, y_j)\}_{j=1}^J\}$.
- Rather than programming from scratch, use **Probabilistic Programming Language** (PPL)
- Specify the *generative model* (forwards simulation); PPL does the rest.
- I'll use STAN; other options include PyMC3 and Turing. (Future session)



## Sample from the posterior using STAN
```{r}
#| message: false
#| warning: false
library(cmdstanr)

filedir <- '~/learn-bayes/STAN-examples/hierarchical-beta-binomial.stan'
HB_beta_binomial <- cmdstan_model(filedir)
HB_beta_binomial$print()

HB_beta_binomial_fit <- HB_beta_binomial$sample(
  data = list(Y = rats$y, N = rats$N, J = nrow(rats)),
  seed = 123,
  chains = 4,
  parallel_chains = 4,
  refresh = 500
)

HB_beta_binomial_fit$summary() |> 
  knitr::kable(digits = 3)
```


## Posterior Means for $\theta_j$ vs MLE

```{r}
#| message: false
# compute the posterior mean for all elements of Theta and append them to rats
Theta_posterior <- HB_beta_binomial_fit$summary() |>  
  as_tibble() |> 
  select(variable, mean, q5, q95) |> 
  filter(str_detect(variable, 'Theta'))

Theta_results <- rats |>
  bind_cols(Theta_posterior) |> 
  mutate(MLE = y / N)

# Whiskers are 90% posterior credible sets
ggplot(Theta_results, aes(x = MLE, y = mean)) +
  geom_point() +
  geom_errorbar(aes(ymin = q5, ymax = q95), width = 0.001) +
  geom_abline(intercept = 0, slope = 1, linetype = 'dashed') +
  labs(x = 'MLE', y = 'Posterior Mean', 
       title = 'Posterior Mean vs MLE: Hierarchical Model') +
  theme_minimal()
```

## Posterior for $(\alpha, \beta)$
```{r}
#| warning: false
#| message: false

# Extract posterior draws for alpha and beta from STAN output
library(posterior)
alpha_beta_posterior <- HB_beta_binomial_fit$draws(
  c('a', 'b', 'phi', 'kappa')) |> 
  as_draws_df()

# Density plot of posterior draws using ggplot
alpha_beta_posterior |> 
  ggplot(aes(x = a, y = b)) +
  geom_density2d_filled() +
  labs(title = 'Posterior', x = expression(alpha),
       y = expression(beta)) + 
  theme_minimal()

# Simulate from prior for (alpha, beta) / (kappa, phi)
library(distributionsrd)
library(patchwork)
nsims <- 4000
alpha_beta_prior <- tibble(phi = runif(nsims), 
                           kappa = rpareto(nsims, xmin = 1, k = 1.5),
                           alpha = kappa * phi,
                           beta = kappa * (1 - phi))

# Density plot of prior draws using ggplot
prior_plot <- alpha_beta_prior |> 
  ggplot(aes(x = phi, y = kappa)) +
  scale_y_log10() +
  geom_density2d_filled() +
  labs(title = 'Prior', x = expression(phi),
       y = expression(kappa)) + 
  theme_minimal()

# Density plot of posterior draws using ggplot
posterior_plot <- alpha_beta_posterior |> 
  ggplot(aes(x = phi, y = kappa)) +
  scale_y_log10() +
  geom_density2d_filled() +
  labs(title = 'Posterior', x = expression(phi),
       y = expression(kappa)) + 
  theme_minimal()

prior_plot + posterior_plot
```


## Posterior Inference for $\theta_{71}$ "by hand"

- Superfluous given STAN output, but just to compare to what we did above
- Given posterior draws for $(\alpha, \beta)$, direct sampling from the posterior for $\theta_{71}$ is easy
- **Exact** formula for the posterior of $\theta_{71}$ given $(\alpha, \beta)$:
$$
\theta_{71} | y_{71}, N_{71}, \alpha, \beta \sim \text{Beta}(y_{71} + \alpha, N_{71} - y_{71} + \beta)
$$
- Draw a sample from this distribution for each draw of $(\alpha, \beta)$
- Identical to posterior mean for $\theta_{71}$ from STAN up to sampling error.

 

```{r}

y_71 <- rats$y[71]
N_71 <- rats$N[71]

theta_71_sims_HB <- alpha_beta_posterior |> 
  mutate(theta_71 = rbeta(n(), a + y_71, b + N_71 - y_71))

theta_71_sims_HB |> 
  pull(theta_71) |>
  mean()

Theta_posterior |>
  filter(str_detect(variable, '71')) |>
  pull(mean)
```


## Comparison with "Crude" Approximation

- Remember how we started out by estimating $(\alpha, \beta)$ using the method of moments?
- Was all this extra work worth it?
- The results are *similar* but not identical
- If we had fewer experiments or more uncertainty in the estimates of $\theta_j$, the differences would be more pronounced.


```{r}
theta_71_crude <- tibble(x = seq(0, 0.6, length.out = 500), 
                         y = dbeta(x, alpha_hat + y_71, beta_hat + N_71 - y_71))

# Compare posterior means for theta_71: cruce versus full hierarchical
theta_71_crude |> 
  mutate(theta_71 = rbeta(n(), alpha_hat + y_71, beta_hat + N_71 - y_71)) |> 
  pull(theta_71) |> 
  mean()

Theta_posterior |>
  filter(str_detect(variable, '71')) |>
  pull(mean)

# Compare posteriors for theta_71: crude versus full hierarchical
theta_71_sims_HB |>
  ggplot(aes(x = theta_71)) +
  geom_density() +
  geom_vline(xintercept = mean(rats$y[71] / rats$N[71]),) +
  labs(title = 'Posterior: Theta_71', x = expression(theta[71]), y = 'Density') +
  theme_minimal() + 
  geom_line(data = theta_71_crude, aes(x = x, y = y), color = 'red', 
            linetype = 'dashed') 
```



## Predicting a *New Experiment* Using the Posterior

Repeat the following steps for each posterior draw of $(\alpha, \beta)$:
1. Draw $(\alpha, \beta)$ from the posterior
2. Draw $\theta_{72}$ from $\text{Beta}(\alpha, \beta)$
3. Draw $y_{72}$ from $\text{Binomial}(N_{72}, \theta_{72})$

```{r}
N_72 <- 15 # sample size in "new" experiment

# Simulate from posterior predictive for y_72
y_72_post_predictive <- alpha_beta_posterior |> 
  mutate(theta_72 = rbeta(n(), a, b),
         y_72 = rbinom(n(), N_72, theta_72))

# Posterior predictive for y_72: bar plot since discrete
y_72_post_predictive |> 
  ggplot(aes(x = y_72)) +
  geom_bar() +
  labs(title = 'Posterior Predictive for y_72', x = 'y_72', y = 'Density') +
  theme_minimal()
```




