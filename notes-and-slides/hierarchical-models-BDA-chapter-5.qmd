---
title: "Hierarchical Models - BDA Chapter 5"
format: 
  html:
    embed-resources: true
---


## Rats Dataset

- Example based on Gelman et al. (2013) "Bayesian Data Analysis" Chapter 5.
- 71 experiments on rats, each with a different number of subjects. 
- Each experiment has a control group and a treatment group.
- We have data from the *control group* for each experiment.
- Observe number of rats in each experiment and number that develop a tumor.
- Goal is to estimate the incidence of tumors in rats from 71 experiments.
- Could be any binary outcome, e.g. success/failure, yes/no, etc.

```{r}
#| message: false
#| warning: false
library(tidyverse)
rats_url <- "http://www.stat.columbia.edu/~gelman/book/data/rats.asc"
rats <- read.table(rats_url, header = TRUE, skip = 2) |> 
  as_tibble() 

rats
```

## Consider the 71st experiment
How should we estimate the incidence of tumors for this experiment?
```{r}
rats |> 
  slice_tail(n = 1)
```

### Textbook Frequentist Approach
$$
\hat{\theta}_{71} = \frac{y_{71}}{N_{71}} = \frac{4}{14} \approx 0.29, \quad \text{SE}(\hat{\theta}_{71}) = \sqrt{\frac{\hat{\theta}_{71}(1 - \hat{\theta}_{71})}{N_{71}}} \approx 0.12
$$

- Approximate 95\% confidence interval is $0.29 \pm 2 \times 0.12$ or $[0.05, 0.53]$.
- Very small sample size; Frequentist asymptotics [can be unreliable]()
- Completely ignores information from the other 70 experiments!

## Quick Review of Beta$(\alpha, \beta)$ Distribution 
- Continuous RV;  support set $[0, 1]$; wide range of shapes
- Parameters: $\alpha, \beta > 0$
- $X \sim \text{Beta}(\alpha, \beta) \iff f(x| \alpha, \beta) \propto x^{\alpha - 1}(1 - x)^{\beta - 1}$ 
- $\text{Uniform}(0, 1)$ is a special case: $\text{Beta}(1, 1)$
$$
\begin{align*}
\mathbb{E}[X] &= \frac{\alpha}{\alpha + \beta}\\
\text{Mode}(X) &= \frac{\alpha - 1}{\alpha + \beta - 2} \quad \text{for } \alpha, \beta > 1\\
\text{Var}(X) &= \frac{\alpha\beta}{(\alpha + \beta)^2(\alpha + \beta + 1)}
\end{align*}
$$

```{r}
plot_beta_examples <- function(alpha, beta, legend_pos = 'topright') {
  x <- seq(from = 0.005, to = 0.995, length.out = 500)
  fx <- map2(alpha, beta, \(a, b) dbeta(x, a, b)) |> 
    reduce(cbind) 
  matplot(x, fx, type = 'l', lwd = 3, xlab = 'x', ylab = 'f(x)')
  my_legend <- map2_chr(alpha, beta, \(x, y) paste0('Beta(', x, ', ', y, ')'))
  legend(legend_pos, legend = my_legend, lty = 1:4, lwd = 2, col = 1:4)
}

plot_beta_examples(alpha = c(4, 2, 1, 0.5), 
                    beta = c(4, 2, 1, 0.5))

plot_beta_examples(alpha = c(0.5, 1, 2), 
                    beta = c(1,   2, 8))

plot_beta_examples(alpha = c(1,   2, 8),
                    beta = c(0.5, 1, 2), 'topleft')
```



## Textbook Bayesian Inference for a Proportion $\theta$
- **Likelihood**: $y|\theta \sim \text{Binomial}(N, \theta)$ 
- **Prior**: $\theta \sim \text{Beta}(\alpha, \beta)$
 

$$
\begin{aligned}
\text{Posterior} &\propto \text{Likelihood} \times \text{Prior} \\
f(\theta | y) &\propto f(y | \theta) \times f(\theta) \\
&\propto \left[\theta^y (1 - \theta)^{N - y}\right] \times \left[\theta^{\alpha - 1} (1 - \theta)^{\beta - 1}\right] \\
&\propto \theta^{y + \alpha - 1} (1 - \theta)^{N - y + \beta- 1}
\end{aligned}
$$

- **Posterior**: $\theta | y \sim \text{Beta}(y + \alpha, N - y + \beta)$.
- **Posterior Mean**: $\frac{y + \alpha}{N + \alpha + \beta}$

## Experiment \# 71
- $N_{71} = 14$; $y_{71} = 4$
- **Posterior**: $\theta \sim \text{Beta}(4 + \alpha, 10 + \beta)$,  **Posterior Mean**: $\hat{\theta}_{71} = \frac{4 + \alpha}{14 + \alpha + \beta}$
- I don't know much about rats and tumors so I'm not sure what $\alpha$ and $\beta$ to use...


```{r}
library(HDInterval)

plot_prior_to_posterior <- function(y, N, alpha, beta) {
  a <- y + alpha
  b <- N - y + beta
  
  theta <- seq(from = 0.005, to = 0.995, length.out = 500)
  prior <- dbeta(theta, alpha, beta)
  posterior <- dbeta(theta, a, b) 
  
  matplot(theta, cbind(prior, posterior), type = 'l', lwd = 2, 
          col = c('blue', 'red'), xlab = expression(theta), ylab = 'Density')
  legend('topright', legend = c('Prior', 'Posterior'), lty = 1, lwd = 2, 
         col = c('blue', 'red'))
  
  posterior_mean <- a / (a + b) 
  hdi_95 <- hdi(qbeta, shape1 = a, shape2 = b, credMass = 0.95)
  mytext <- paste0('Posterior Mean: ', round(posterior_mean, 2), 
         '\n95% HPDI: [', round(hdi_95[1], 2), ', ', round(hdi_95[2], 2), ']')
  text(0.5, 0.5 * max(max(prior), max(posterior)), mytext, adj = 0, 
       cex = 1.2, col = 'black')
}

plot_prior_to_posterior(y = 4, N = 14, alpha = 1, beta = 1)
plot_prior_to_posterior(y = 4, N = 14, alpha = 1, beta = 2)
plot_prior_to_posterior(y = 4, N = 14, alpha = 2, beta = 8)
plot_prior_to_posterior(y = 4, N = 14, alpha = 0.5, beta = 1)
```

## How can we do better?
- Results aren't too sensitive to reasonable choices of $\alpha$ and $\beta$.
- But we're still quite uncertain about the true value of $\theta_{71}$!
- **Idea**: use data from other 70 experiments to inform our prior for the 71st.


## First Idea: Pooling Data

- Suppose that the *true* incidence of tumors in rats is the same across all experiments. 
- Then it would make sense to *pool* the data to estimate $\theta_{71}$
- One way to think of this: pool the data from experiments 1-70 to "estimate" a prior for experiment 71.
- Then proceed as before. 
- Equivalent way to think about it: pool all 71 experiments to learn about the true incidence of tumors in rats.

## A Pooled Prior from Experiments 1-70
```{r}
#| echo: false
y_1_to_70 <- rats |> 
  slice_head(n = -1) |> 
  pull(y) |> 
  sum()

N_1_to_70 <- rats |> 
  slice_head(n = -1) |> 
  pull(N) |> 
  sum()
```

- **Prior**: $\theta \sim \text{Beta}(\alpha, \beta)$
- **Likelihood**: $y_{j} | \theta \sim \text{indep. Binomial}(N_j, \theta)$
- **Equivalently**: $\sum y_j |\theta \sim \text{Binomial}\left(\sum N_j, \theta\right)$
- **Posterior**: $\theta | \sum y_j \sim \text{Beta}\left(\sum y_j + \alpha, \sum N_j - \sum y_j + \beta\right)$
- $\sum y_j=$ `r y_1_to_70` and $N_j=$ `r N_1_to_70` for experiments 1-70, so $\alpha$ and $\beta$ will barely matter
- For simplicity: $\alpha = \beta = 1 \implies \theta | (y_1, \dots y_{70}) \sim \text{Beta}(264, 1463)$

## Inference for Experiment 71 using Pooled Prior

```{r}
plot_prior_to_posterior(y = 4, N = 14, alpha = 264, beta = 1463)
```

- Very precise inference for $\theta_{71}$
- But the data from Experiment 71 is basically ignored!
- Swamped by the prior constructed from experiments 1-70.
- Feature or bug?
  - Feature if we *really believe* same $\theta$ for all experiments
  - Bug if we think $\theta$ might vary across experiments
  
  
## Better Idea: Hierarchical Model

- Rather than a single $\theta$ for all experiments, allow a different one $\theta_j$ for each.
- Treat $(\theta_1, \theta_2, \dots, \theta_{70})$ as draws from a *common distribution* 
$$
\theta_j | \alpha, \beta \sim \text{independent Beta}(\alpha, \beta)\quad \text{for } j = 1, 2, \dots, 71
$$
- Conditional on $(\alpha, \beta)$ the parameters $\theta_1, \dots, \theta_{71}$ are independent
- Known $(\alpha, \beta) \implies$ no extra information about $\theta_{71}$ from other experiments 
- Unconditionally, the parameters $\theta_1, \dots, \theta_{71}$ are *dependent*
- Unknown $(\alpha, \beta) \implies$ other experiments *indirectly* inform us about $\theta_{71}$ through the info they provide about $(\alpha, \beta)$.

## Exchangeability

- **Recall**: unconditionally, the parameters $\theta_1, \dots, \theta_{71}$ are *dependent*
- But because they come from a *common distribution* they are *identically distributed*.
- In fact we can say more: they are **exchangeable**: the joint distribution of $(\theta_1, \dots, \theta_{71})$ is invariant to permutations of the indices (c.f. *strong stationarity* in time series)

## What does exchangeability mean in practice?

- A kind of "symmetry" between the experiments
- They're different, but we don't know *how* they're different
- E.g.\ the experimental conditions may vary but we *don't know* for example, that experiments 1-10 were performed in Lab A and experiments 11-28 in Lab B.
- If we know more about the experiments, exchangeability would be violated.
- But in that case we could use the extra information to build an *even better model* in which exchangeability holds after we condition on what we know.
- This is a bit subtle, but is discussed in some detail in Meager (2019).


## The Challenge: $\theta_1, \dots, \theta_{71}$ are *unobserved*

- **Unobserved**: $\theta_j | \alpha, \beta \sim \text{independent Beta}(\alpha, \beta)$
- **Observed**: $y_j | \theta_j \sim \text{independent Binomial}(N_j, \theta_j)$
- We want to infer $\theta_{71}$, but we don't know $\alpha$ and $\beta$.
- Other experiments contain information about $\alpha$ and $\beta$ but don't know $\theta_1, \dots, \theta_{70}$ either! 
- Somehow we need to *infer* $(\alpha, \beta)$ from the observed data and then use them to infer $\theta_{71}$.
- Start with a simple and intuitive idea that is *slightly wrong* but gets the idea across.
- After that I'll show you how to do things the right way!

## A Crude Approximation

- **Unobserved**: $\theta_j | \alpha, \beta \sim \text{independent Beta}(\alpha, \beta)$
- **Observed**: $y_j | \theta_j \sim \text{independent Binomial}(N_j, \theta_j)$
- **Idea**: treat *estimates* $\hat{\theta}_j$ as the *true* parameters $\theta_j$; use them to estimate $(\alpha, \beta)$.
- In particular: set $\hat{\theta}_j = \frac{y_j}{N_j}$ and use the method of moments to estimate $(\alpha, \beta)$.

## Method of Moments Estimation of $(\alpha, \beta)$

- Suppose we observed $\theta_1, \dots, \theta_{70} \sim \text{iid Beta}(\alpha, \beta)$.
- We know how the mean and variance of this distribution relate to $(\alpha, \beta)$
$$
\begin{align*}
\mathbb{E}[\theta_j] &= \frac{\alpha}{\alpha + \beta}\\
\text{Var}[\theta_j] &= \frac{\alpha\beta}{(\alpha + \beta)^2(\alpha + \beta + 1)}
\end{align*}
$$
- Solving for $\alpha$ and $\beta$ gives
$$
\begin{align*}
\alpha &= \mathbb{E}[\theta_j] \times \left(\frac{\mathbb{E}[\theta_j] \times (1 - \mathbb{E}[\theta_j])}{\text{Var}[\theta_j]} - 1\right)\\
\beta &= (1 - \mathbb{E}[\theta_j]) \times \left(\frac{\mathbb{E}[\theta_j] \times (1 - \mathbb{E}[\theta_j])}{\text{Var}[\theta_j]} - 1\right)
\end{align*}
$$
- Replace $\mathbb{E}[\theta_j]$ and $\text{Var}[\theta_j]$ with sample mean/variance $\theta_j$ to yield estimates $(\hat{\alpha}, \hat{\beta})$.
- Since $\theta_j$ unobserved, replace with $\hat{\theta}_j = \frac{y_j}{N_j}$.

```{r}
# Estimates of theta for experiments 1-70
theta_hat <- rats |> 
  slice_head(n = -1) |> 
  mutate(p = y / N) |> 
  pull(p)

# Histogram of estimates
hist(theta_hat, main = 'Estimates from Experiments 1-70', 
     xlab = expression(hat(theta)), ylab = 'Frequency', col = 'lightblue')

# Method of moments estimates of alpha and beta based on experiments 1-70
theta_mean <- mean(theta_hat)
theta_var <- var(theta_hat)
alpha_hat <- theta_mean * (theta_mean * (1 - theta_mean) / theta_var - 1)
beta_hat <- (1 - theta_mean) * (theta_mean * (1 - theta_mean) / theta_var - 1)
c(alpha = alpha_hat, beta = beta_hat)

# Bayesian Posterior for theta_71 using alpha_hat and beta_hat
plot_prior_to_posterior(y = 4, N = 14, alpha = alpha_hat, beta = beta_hat)
title(main = 'Prior from Experiments 1-70: Exchangeable Thetas')

# Contrast with "vague" prior: alpha = beta = 1
plot_prior_to_posterior(y = 4, N = 14, alpha = 1, beta = 1) 
title(main = 'Beta(1, 1) Prior')

# Contrast with full pooling
plot_prior_to_posterior(y = 4, N = 14, alpha = 264, beta = 1463)
title(main = 'Prior from Expreiments 1-70: Same Theta')
```

## Lessons from the Crude Approximation
- "No Pooling" prior: $\text{Beta}(1, 1)$ 
  - Gives 71st experiment **too much weight** when estimating $\theta_{71}$
  - Completely ignores the other 70 experiments!
  - High variance; tiny bias 
- "Full Pooling" prior: same $\theta$ for all experiments 
  - Gives 71st experiment **too little weight** when estimating $\theta_{71}$
  - Almost completely ignores data from 71st experiment!
  - Tiny variance; large bias
- "Partial Pooling" prior: assumes $\theta_j|(\alpha, \beta) \sim \text{indep Beta}(\alpha, \beta)$ 
  - **strikes a balance** between the full and partial pooling
  - Uses data from all 71 experiments to estimate $\theta_{71}$
  - Low variance; low bias
  
  
## Problems with the Crude Approximation

- Ignores the fact that $\theta_j$ are *estimates* rather than true parameters.
- As such, *understates* our true uncertainty about $(\alpha, \beta)$.
- Method of moments formulas assume that $\hat{\theta}_j$ are draws from a Beta distribution but they're not!
- E.g.\ several of the $\hat{\theta}_j$ are *exactly* zero but the Beta distribution is continuous!
- Ignores uncertainty in estimates of $(\alpha, \beta)$ as well: just plugs in estimates
- What if we wanted to estimate *each* of the $\theta_j$ simultaneously? 
- Shouldn't re-use the same data twice: need to re-estimate $(\alpha, \beta)$ for each $\theta_j$, data from experiments *besides* $j$.

## A Fully Bayesian Hierarchical Model

- Always start by writing down a full, generative probabilistic model!
- Using the shorthand $\phi$ for $(\alpha, \beta)$, the *conditional* joint distribution of the $\theta_j$ is
$$
f(\theta_1, \dots, \theta_{71} | \phi) = f(\theta_1 | \phi) \times \dots \times f(\theta_{71} | \phi) = \prod_{j = 1}^{J} f(\theta_j | \phi)
$$
- By the law of total probability, *unconditional* joint distribution is 
$$
f(\theta_1, \dots, \theta_{71}) = \int f(\theta_1, \dots, \theta_{71} | \phi) \times f(\phi) d\phi = \int \left[\prod_{j = 1}^{J} f(\theta_j | \phi) \times f(\phi)\right] d\phi
$$
- Joint distribution of the $\theta_j$ is a *mixture* iid conditional distributions $f(\theta_j | \phi)$, with mixing distribution $f(\phi)$.

## Things to add
- Explain the full model: need a **hyperprior**
- Explain how it's easy to simulate *forwards* from the model
- Bayes does the reverse; this is harder and we'll use Monte-Carlo methods
- standard exponential priors for $\alpha$ and $\beta$ should work
- Show them the sense in which this is a vague prior; maybe simulate it forwards using the observe values of $N_j$.
- Show a STAN implementation but don't get bogged down in the syntax
- Make a version of figure 5.4 from Gelman and possibly Figure 5.3 as well



## Initial notes

Some things to illustrate using the rats example:

1. Estimating the proportion for experiment 71 ignoring all the other experiments seems like a bad idea: surely they should tell us something. If we want to estimate all of the proportions from the different experiment, we can appeal to a James-Stein type idea to argue for shrinkage.
1. What happens if we assume that experiments 1-70 are estimating the *same* parameter as experiment 71? In this case we'd have a very strong prior and basically ignore the data from the 71st experiment! This is a bad idea.
1. A first attempt at using all the data would be to estimate a common Beta prior for all the parameters of each experiment, using data from experiments 1-70. A crude version of this ignores the fact that the parameters from experiments 1-70 are estimates rather than true parameter values.
1. A more sophisticated version would be to try Empirical Bayes. Somewhere or other I have a link or reference to the Binomial version: it's a bit trickier than the Poisson case. I guess there are really two options: NP Empirical Bayes or Parametric Empirical Bayes with a Beta-Binomial.
1. Could then try the full-Bayes approach. There are at least two versions here. One would be to use an arcsine transformation so we can use normal theory. Another would be to do something that explicitly models the Beta distribution. Perhaps the one downside of the normal approximation here is that it wouldn't fully illustrate how things work *in general* since we'd typically have means and variances that aren't entagled as they are in a proportions problem.



