---
title: "Poisson Regression with STAN"
format: 
  html:
    embed-resources: true
---

## What is this?
In this document, I implement the Poisson regression models from `poisson-regression.qmd` that were implemented using `ulam()` from the `rethinking` package, but now I use STAN instead. I also re-implement the Poisson-normal mixture from `poisson-normal-mixture.qmd`, again using STAN rather than `ulam()`. 



## Plain Vanilla Poisson Regression
OK, this isn't one of the examples from `poisson-regression.qmd` but I wanted to start with the simplest possible example!
$$
\begin{align*}
Y_i &\sim \text{Poisson}(\lambda_i)\\
\log (\lambda_i) &= \alpha + \beta (X_i - \bar{X})/S_X\\
\alpha &\sim \text{Normal}(3, 0.5)\\
\beta &\sim \text{Normal}(0, 0.2)
\end{align*}
$$
These are reasonable weakly informative priors in a setting where counts are generally between 0 and 100, given that $X_i$ enters the model as a z-score.

Now, we'll follow procedure outlined in `CmdStanR-getting-started.qmd`. First, load `cmdstanr` and check that everything is set up correctly:
```{r}
library(cmdstanr)
check_cmdstan_toolchain()
```

Next compile the first model, which is stored in `poisson-regression-basic.stan` in the current working directory. Since this directory is associated with an Rstudio project, there is no need to provide an absolute path:
```{r}
basic_poisreg <- cmdstan_model('poisson-regression-basic.stan')
```
Now we can look at the path to the executable:
```{r}
basic_poisreg$exe_file()
```
and print out the underlying `.stan` file:
```{r}
basic_poisreg$print()
```
It's worth commenting on this a bit, since it took me a while to get it working. (Fortunately, STAN gives relatively informative error messages!) Here are some errors that I made initially:

- A STAN `vector` can only store real values, but an `array` can store anything, including integers that are bounded.
- Rstudio uses `rstan` for its `.stan` [syntax checking](https://github.com/rstudio/rstudio/issues/6802), but the version of `rstan` that I installed from `CRAN` was out of date, so it didn't support the `array` type. This meant that the editor highlighted an "error" that was not in fact an error, and would not have created any problems given that I'm using CmdStanR. To fix this I simply installed the latest version of `rstan` following [these instructions](https://discourse.mc-stan.org/t/parser-error-when-running-birats-example-in-rstan/29336).
- Forgetting a semicolon! So easy to miss!
- Getting confused about how you can and cannot mix matrix / vector / scalar [operations](https://mc-stan.org/docs/functions-reference/matrix-arithmetic-operators.html).
- Forgetting to check the types that are expected by [`poisson_log_glm()`](https://mc-stan.org/docs/functions-reference/poisson-log-glm.html). This function is only worth using if you have more than one predictor.
- Not realizing that a `transformed data` block must come [before](https://mc-stan.org/docs/reference-manual/overview-of-stans-program-blocks.html) the `parameters` block.

And here are some other comments on the `.stan` file:

- The [`poisson_log()` function](https://mc-stan.org/docs/functions-reference/poisson-distribution-log-parameterization.html) avoids the need to exponentiate `alpha + beta * x`. In other words, it lets us express the model on the log scale. This is mainly for convenience, but I think it actually does squeeze out a bit of efficiency when it comes to calculating gradients. Its big brother [`poisson_log_glm()`](https://mc-stan.org/docs/functions-reference/poisson-log-glm.html) can *definitely* give efficiency gains. This removes the need for multiplication of `x` by `beta` but is really intended for the case where there are multiple predictors and the multiplication in question is matrix multiplication. That's where there are efficiency gains in the gradient calculation.
- It doesn't matter whether the "likelihood" or the "priors" come first in the model block. They are both treated the same way, since this block merely [increments the log posterior](https://discourse.mc-stan.org/t/correct-ordering-of-lines-in-the-model-block/661/3), and it doesn't matter in which order you take a summation, unless there are numerical issues of some kind.
- The `transformed data` block isn't necessary, but it's convenient. We could transform $X$ within R, but this prevents us from making a mistake and providing data on the wrong scale without realizing it.

Now let's simulate some data: 
```{r}
set.seed(1848)
n <- 100
x <- runif(n, -1, 2)
y <- rpois(n, exp(0.8 + 0.4 * scale(x)))
dat <- list(N = n, x = x, y = y)
rm(n, x, y)
```
and then estimate the model:
```{r}
fit1 <- basic_poisreg$sample(
  data = dat, 
  seed = 1234, # random seed for MCMC
  chains = 4, 
  parallel_chains = 4, 
  refresh = 500 # print status update after every 500 iterations
)
```

Now a quick summary of the posterior to make sure it worked. Recall that the true parameter values were $\alpha = 0.8$ and $\beta = 0.4$. Looks good!
```{r}
fit1$summary() |> 
  knitr::kable(digits = 2)
```


## Varying-Effects Poisson Regression

This is a slightly more complicated version of the above, based on an example from *Statistical Rethinking*. The goal is to model the total number of tools in a society, `total_tools`, in terms of `population` and the extent of contact with other islands, `contact`. The first model is as follows:
$$
\begin{align*}
T_i &\sim \text{Poisson}(\lambda_i)\\
\log \lambda_i &= \alpha_{\text{CID}[i]} + \beta_{\text{CID}[i]} \text{(logPopZ)}_i\\
\alpha_j &\sim \text{Normal}(3, 0.5)\\
\beta_j &\sim \text{Normal}(0, 0.2)
\end{align*}
$$
where $T_i$ is `total_tools`, $\text{(logPopZ)}_i$ is a centered and standardized version of the logarithm of `population` and $\text{CID}[i]$ is a categorical variable that indicates the value of `contact` for society $i$.
In other words, this is a model in which $\alpha$ and $\beta$ vary with `contact`.
Equivalently, the model includes a full set of dummy variables that encode `contact` along with interactions between these dummies and the log of `population`.

```{r}
#| message: false
#| warning: false
library(tidyverse)
library(rethinking)
data("Kline")
dat <- as_tibble(Kline)
rm(Kline)
dat

dat <- dat |> 
  mutate(cid = if_else(contact == 'low', 1, 2),
         lpop = log(population), 
         lpopz = (lpop - mean(lpop)) / sd(lpop)) |> 
  select(total_tools, cid, lpopz)
```

Let's start by looking at the STAN code that is automatically generated by `ulam()` from `rethinking` when we implement the model as described in the book. By setting `sample = FALSE` we set up the model without actually running anything. Then we can used `stancode()` to extract the underlying STAN code:
```{r}
m11_10 <- ulam(
  alist(
    total_tools ~ dpois(lambda),
    log(lambda) <- a[cid] + b[cid] * lpopz,
    a[cid] ~ dnorm(3, 0.5),
    b[cid] ~ dnorm(0, 0.2)
  ), data = dat, sample = FALSE 
)

stancode(m11_10)
```

This is fairly clear, but there are a few ways that it could be cleaned up and optimized, drawing on my simple Poisson regression example from above. The first is to both the number of observations and the number of contact indicators as data rather than hard-coding them to equal `10` and `2`. The second is to use `poisson_log()` rather than constructing `lambda` and exponentiating it. This is better for numerical stability. [This example](https://mc-stan.org/docs/stan-users-guide/hierarchical-logistic-regression.html) suggests some ways of eliminating `for` loops. The reason to avoid `for` loops is not that they're slow in STAN: everything compiles down to C++ so there's no speed penalty from loops as such. Instead it's an issue of more efficiently computing the gradients used in Hamiltonian MCMC. But in this case, there's only a single `for` loop and it doesn't seem straightforward to eliminate it: this is where the varying means $\lambda_i$ are constructed by indexing into the appropriate group for each observation. For this reason, I'll content myself with making only minor modifications, including transforming `population` within STAN:  

```{r}
m11_10_stan <- cmdstan_model('poisson-regression-rethinking-11-10.stan')
```
This time my STAN program compiled on the first try with no errors! Clearly I'm making progress. 
```{r}
m11_10_stan$print()
```

Now we'll set up the data to match the variable names I used in my STAN program and the fact that I transform `pop` within the program rather than doing so in advance:
```{r}
data("Kline")
dat <- list(N_obs = nrow(Kline),
            N_groups = length(unique(Kline$contact)),
            group = if_else(Kline$contact == 'low', 1, 2),
            pop = Kline$population,
            total_tools = Kline$total_tools)
rm(Kline)
```

Now we can estimate the model. The first time I ran this it threw an error: it turned out that I *did* have a mistake in my STAN program, but one that only became apparent at runtime: I declared one of the data arrays to be of the wrong size, and STAN caught this as soon as I passed in the data.
```{r}
fit2 <- m11_10_stan$sample(
  data = dat,
  seed = 1234,
  chains = 4, 
  parallel_chains = 4,
  refresh = 500
)
```
Now let's take a quick look at the posterior to see if it agrees with the results from `poisson-regression.qmd` computed via `ulam()`. Yes: everything looks good, bearing in mind that `precis()` reports 89\% rather than 90\% posterior credible intervals!
```{r}
fit2$summary() |> 
  knitr::kable(digits = 2)
```

## Structural Poisson Regression Model

This is the same tools/population example as above but with a structural model for the production of tools.
Suppose that the change in the average number of tools from one period to the next is given by
$$
\Delta T = \alpha P^\beta - \gamma T.
$$
where $P$ is population on the *raw* scale. The equilibrium number of tools is
$$
T^* = \frac{\alpha}{\gamma} P^\beta.
$$
This is a structural model.
To turn it into a *statistical* model, we need a likelihood i.e.\ a distribution for *noise* around $T^*$. 
Since `total_tools` is a count variable with no upper bound, the maximum entropy distribution is a Poisson. 
So we specify the model as follows
$$
\begin{align*}
T_i &\sim \text{Poisson}(\lambda_i) \\
\lambda_i &= \alpha_{\text{CID}[i]} P^{\beta_{\text{CID}[i]}}/\gamma.
\end{align*}
$$
Now we'll set up the data as in *Statistical Rethinking* and extract the STAN code from `ulam()`, using the same priors as the book:
```{r}
#| warning: false
#| message: false
data(Kline)
dat2 <- as_tibble(Kline) 
rm(Kline)
dat2 <- dat2 |> 
  mutate(cid = if_else(contact == 'low', 1, 2)) |> 
  select(population, cid, total_tools)

m11_11 <- ulam(
  alist(
    total_tools ~ dpois(lambda),
    lambda <- exp(a[cid]) * population^b[cid] / g,
    # Not sure why the book uses a normal and then exponentiates rather
    # than just using a lognormal. Maybe to avoid numerical issues?
    a[cid] ~ dnorm(1, 1),
    b[cid] ~ dexp(1),
    g ~ dexp(1)
  ), data = dat2, sample = FALSE
)
stancode(m11_11)
```
This is quite straightforward and very similar to the example from above. But just for fun, let's make a few small changes to the implementation. First, we'll express the model on the log scale: 
$$
\log(\lambda_i) = \log(\alpha_{\text{CID}[i]}) + \beta_{\text{CID}[i]}\log(P_i) - \log(\gamma).
$$
This makes it clear--if it wasn't already--that $\gamma$ is not identified in the Frequentist sense. Accordingly, define $\delta_{\text{CID}[i]} = \log(\alpha_{\text{CID}[i]}/\gamma)$, yielding the re-parameterized model
$$
\log(\lambda_i) = \delta_{\text{CID}[i]} + \beta_{\text{CID}[i]} \log(P_i).
$$
And since $\gamma$ isn't identified in any case, re-define $\alpha_{\text{CID}[i]}$ to be the ratio of the original parameter and $\gamma$ so that $\alpha_{\text{CID}[i]} = \exp(\delta_{CID}[i])$. We'll suppose that the parameter of interest is really $\alpha$ rather than $\delta$, giving us an opportunity to use a `transformed parameters` block in STAN. Note that our results here will not exactly correspond to those in the book, since we won't place a prior on the unidentified parameter $\gamma$.
```{r}
m11_11_stan <- cmdstan_model('poisson-regression-rethinking-11-11.stan') 
```

Here's the STAN program:
```{r}
m11_11_stan$print()
```

A few points worth noting:

- I explicitly set a lower bound of zero for $\beta$. This may seem strange given that the exponential prior already reflects this, but that's not actually how STAN works. There's some discussion on page 374 of *A Student's Guide to Bayesian Statistics*. In practice, if you have a parameter that is constrained you should impose this constraint in the `parameters` block.
- I use a `transformed parameters` block to construct the structural parameter $\alpha_\text{CID[i]}$ on its original non-log scale within STAN, rather than after the fact. See page 382 of *A Student's Guide to Bayesian Statistics*. No Jacobian is required for this, since we are transforming *after* sampling rather than before. See pages 398-401 of *A Student's Guide to Bayesian Statistics*. 
- I initially got a strange warning about "incomplete final line..." but it turns out that this is [harmless](https://discourse.mc-stan.org/t/incomplete-final-line-found/6907). To eliminate it, simply add a completely blank line to the end of the `.stan` file.

Now we can sample the model and look at the output. Remember that this model isn't quite the same as the one from the book, since I've changed the parameterization:
```{r}
data("Kline")
dat <- list(N_obs = nrow(Kline),
            N_groups = length(unique(Kline$contact)),
            group = if_else(Kline$contact == 'low', 1, 2),
            pop = Kline$population,
            total_tools = Kline$total_tools)
rm(Kline)

fit3 <- m11_11_stan$sample(
  data = dat,
  seed = 1234,
  chains = 4,
  parallel_chains = 4,
  refresh = 500
)

fit3$summary() |> 
  knitr::kable(digits = 2)
```

## Poisson Model with Offsets / Exposure

If there are $\lambda$ events per unit time, then in an interval of length $\tau$ there will be, on average, $\mu = \lambda \tau$ events.
If, as above, we have a linear model on the log scale for $\lambda_i$, then
$$
\log \mu_i = \log (\lambda_i \tau_i) = \log \tau_i + \log \lambda_i = \log \tau_i + \alpha + \beta x_i.
$$
In other words: to translate from a model for the *rate* $\lambda_i$ to a model for the *mean number of events* $\mu_i$, on the log scale we merely need to subtract $\log \tau_i$.

Here's a little simulation example based on: 11-12 from *Statistical Rethinking*.
There are two monasteries: the first has a rate of $\lambda = 1.5$ manuscripts per day and records daily totals; the second has a rate of $\lambda = 0.5$ manuscripts per day but records weekly totals.
```{r}
set.seed(54321)
n0 <- 100 # observe daily counts for 30 days 
y0 <- rpois(n0, lambda = 1.5) # rate of 1.5 manuscripts / day 

n1 <- 20 # observe weekly counts for 20 weeks
y1 <- rpois(n1, lambda = 7 * 0.5) # rate of 0.5 manuscripts / day times 7 days

manuscripts <- tibble(y = c(y0, y1),
                      monastery = c(rep(0, n0), rep(1, n1)), # monastery dummy
                      exposure = c(rep(1, n0), rep(7, n1)), # exposure in days
                      log_days = log(exposure))
```

For this example the book uses a Laplace approximation to the posterior rather than HMC. I'll use STAN and this time I'll try to write the model totally from scratch without looking at any examples! I'll also parameterize it differently, in keeping with the more usual practice with varying coefficient models.

**Important!** The first time I did this, I got incorrect results but no error messages! There was a very subtle error in the code and it took me a long time to figure out. Because this document is about learning STAN, I'll go through the mistake, show why it's wrong, and show how to correct it. Here's the `.stan` file for the **wrong version**, where I've included a print statement in the `transformed data` block that will reveal the error later on when we fit the model:

```{r}
m11_12_stan_WRONG <- cmdstan_model('poisson-offsets-rethinking-11-12-WRONG.stan')
m11_12_stan_WRONG$print()
```
Now we'll set up the data, and estimate the model. **Notice that the results are definitely wrong!** The credible set for `d` should be fairly tight and centered around one but it's not! We can see what's wrong from the debugging print statement: it's evaluating $\log(7)$ as one! In other words it's truncating!
```{r}
dat <- list(N_obs = nrow(manuscripts), 
            days = manuscripts$exposure,
            monastery = manuscripts$monastery + 1, # number them 1 and 2
            manuscripts = manuscripts$y)

fit4_WRONG <- m11_12_stan_WRONG$sample(
  data = dat,
  seed = 1234,
  chains = 4, 
  parallel_chains = 4,
  refresh = 500
)

fit4_WRONG$summary() |> 
  knitr::kable(digits = 2)
```

Just like in C++, `log()` applied to an integer in STAN returns another integer! This is easy to fix: simply store `pop` as `real` and everything works as expected:
```{r}
m11_12_stan <- cmdstan_model('poisson-offsets-rethinking-11-12.stan')
m11_12_stan$print()

fit4 <- m11_12_stan$sample(
  data = dat,
  seed = 1234,
  chains = 4, 
  parallel_chains = 4,
  refresh = 500
)

fit4$summary() |> 
  knitr::kable(digits = 2)
```
## Zero-inflated Poisson Model

Continuing with the Monks and manuscripts spiel, Example 12-3 from *Statistical Rethinking* fits a zero-inflated Poisson model of the form:
$$
\begin{align*}
Y_i &\sim \text{ZIPoisson}(p, \lambda)\\
\text{logit}(p)  &= \alpha_p \\
\log(\lambda)  &= \alpha_\lambda\\
\alpha_p &\sim \text{Normal}(-1.5, 1)\\
\alpha_\lambda &\sim \text{Normal}(1, 0.5)
\end{align*}
$$
The idea is that the monks take the day off and spend it drinking instead with probability $p$. When they drink, they produce zero manuscripts. When they don't drink, they produce a Poisson-distributed number of manuscripts, with rate $\lambda$. Hence, the distribution of $Y|p,\lambda$ is given by 
$$
\mathbb{P}(Y=y|\lambda, p) =\left\{
\begin{array}{ll}
p + (1 - p)\exp(-\lambda), & y = 0 \\
 (1 - p) \frac{\lambda^y \exp(-\lambda)}{y!}, & y > 0
\end{array}\right. 
$$
The indicator for whether or not the monks drink is an unobserved latent variable. Since the current version of STAN can't sample discrete parameters, we instead "integrate out" the latent variable when we write down the above distribution.

Here's the simulated data and `ulam()` model
```{r}
p_true <- 0.2 # Monks drink on 20% of days
lambda_true <- 1 # When working, monasteries average 1 manuscript / day

n <- 365 # A year's worth of daily data on manuscript production

set.seed(365) # This is the seed used in the book

drink <- rbinom(n, 1, p_true) # indicator for whether the monks drink
y <- (1 - drink) * rpois(n, lambda_true) # manuscripts produce

m12_3 <- ulam(
  alist(
    y ~ dzipois(p, lambda),
    logit(p) <- ap,
    log(lambda) <- al,
    ap ~ dnorm(-1.5, 1),
    al ~ dnorm(1, 0.5)
  ), data = list(y = y), sample = FALSE
)

stancode(m12_3)
```

This is the first time we've encountered the `target += [SOMETHING]` syntax instead of a "sampling statment" of the form `[SOMETHING] ~ [DISTRIBUTION]([pars])` I found this extremely confusing at first. The discussion discussion on pages 373-374 of *A Student's Guide to Bayesian Statistics* was very helpful, as was [this article](https://jsocolar.github.io/jacobians/), which is ostensibly about why and when we need to account for a Jacobian term. The following is my overview of both.

The notation `~` is convenient, but a bit misleading. Unlike JAGS and BUGS, STAN is an *imperative* rather than a *declarative* programming language. What we're actually doing when we write a `.stan` file is implementing the **target density** in a computer program. The variable `target` is where STAN stores this object. Once we've implemented the target density, STAN takes over and does the rest: it uses the NUTS sampler to draw from the posterior. But what on earth is the **target density** in the first place?

The reason for MCMC is that it's typically hard or impossible to compute the denominator from Bayes Theorem, the so-called "normalizing constant" or "marginal likelihood" or "marginal data density." Recall that the denominator does *not* depend on the parameters: it's just a constant that makes the posterior integrate to one. Like all MCMC algorithms, HMC works with an unnormalized posterior: any density that is *proportional* to the true posterior. STAN calls this the **target density**. Again, literally any density that is proportional to the posterior works. The whole point of MCMC is that we don't know the true normalizing constant. 

Here's an example. Consider a vector of $N$ iid observations $\mathbf{Y}$ from a distribution with parameter $\theta$. Bayes theorem, without the normalizing constant, gives
$$
\begin{align*}
\pi(\theta|\mathbf{Y}) &\propto f(\mathbf{Y}|\theta) \times \pi(\theta) \\
&= \prod_{i=1}^N f(Y_i|\theta)\times \pi(\theta).
\end{align*}
$$
STAN actually works with the un-normalized *log posterior*, namely:
$$
\begin{align*}
\log \pi(\theta|\mathbf{Y}) &\propto \log f(\mathbf{Y}|\theta) + \log \pi(\theta)\\
&= \left[\sum_{i=1}^n \log f(Y_i|\theta) \right] + \log \pi(\theta)
\end{align*}
$$
What a prior sampling statement such as `theta ~ normal(0, 1);` actually does is *increment* the log posterior. Similarly, a "likelihood" sampling statement such as `y ~ normal(theta, 1)` actually does is loop over all elements of the vector `y` to increment the log posterior by 
$$
\log f(Y_i|\theta) = (\text{Constant}) - \frac{1}{2} (y_i - \theta)^2.
$$
Sampling statements drop the constant term. Another way of building up the log posterior that keeps the constants but is more explicit about what's actually happening is the following:
```
for(i in 1:10) {
  target += normal_lpdf(y[i] | mu, 1) 
}
```
The variable `target` is where STAN stores the **logarithm of the target density**. We don't have to create the variable `target` since STAN creates it for us and initializes it to zero. This is arbitrary but doesn't make any difference since we can always subtract a constant from the log posterior. (It's equivalent to multiplying the un-normalized posterior by a constant.) So what the above block of code really does is loop over the data to increment `target` to reflect the contribution from each observation. This is worth emphasizing:

> When we write a `.stan` file, what we're *actually* doing is specifying a computer program to calculate the log of the un-normalized posterior, a quantity that STAN refers to as `target`. This is the only user-provided input that STAN needs to implement the NUTS sampler.

Now we can start to unpack the STAN code used to fix the zero-inflated Poisson model. Recall the associated probability mass function from above, expressed in terms of $\lambda$ and $p$:
$$
\mathbb{P}(Y=y|\lambda, p) =\left\{
\begin{array}{ll}
p + (1 - p)\exp(-\lambda), & y = 0 \\
 (1 - p) \frac{\lambda^y \exp(-\lambda)}{y!}, & y > 0
\end{array}\right. 
$$
Hence, for a sample of $N$ iid observations from this distribution, the log-likelihood is given by
$$
\sum_{i=1}^n \left\{\mathbf{1}(y_i = 0) \log\left[ p + (1 - p) \exp(-\lambda)\right] + \mathbb{1}(y_i>0)\log\left[(1 - p) \frac{\lambda^{y_i}\exp(-\lambda)}{y_i!}\right] \right\}.
$$
Using the shorthand $\texttt{dpois}(y_i|\lambda)$ to denote the Poisson$(\lambda)$ probability mass function evaluated at $y_i$, we can re-write this as
$$
\sum_{i=1}^n \left\{\mathbf{1}(y_i = 0) \log\left[ p + (1 - p) \texttt{dpois}(0|\lambda)\right] + \mathbb{1}(y_i>0)\log\left[(1 - p) \texttt{dpois}(y_i|\lambda)\right] \right\}.
$$
Now let's phrase this in terms of an update to `target`. If $y_i = 0$ then we need to add
$$
\log\left[ p + (1 - p) \texttt{dpois}(0|\lambda)\right]
$$
to `target`. If instead $y_i \neq 0$, then we need to add
$$
\log(1-p) + \log \left[\texttt{dpois}(y_i|\lambda)\right]
$$
to `target`. This is precisely the logic we'll implement in STAN, with `if ... else` and a `for` loop. To ensure numerical stability, however, we'll use a few helper functions provided by STAN. The following discussion is based on the chapter on [zero-inflated and hurdle models](https://mc-stan.org/docs/stan-users-guide/zero-inflated.html) from the STAN manual, along with the chapter on [vectorizing mixtures](https://mc-stan.org/docs/stan-users-guide/vectorizing-mixtures.html). There is also some information on optimizing the model [here](https://mc-stan.org/docs/stan-users-guide/zero-inflated.html#optimizing-the-zero-inflated-poisson-model) that I'll pass over for now.

The first function we'll use is [`log1m()`](https://mc-stan.org/docs/functions-reference/composed-functions.html). This is nothing more than a numerically stable implementation of $f(x) = \log(1 - x)$.
The second function we'll use is [`log_mix()`](https://mc-stan.org/docs/functions-reference/composed-functions.html). This function is defined as follows:
$$
\texttt{log\_mix}(\theta, \lambda_1, \lambda_2) = \log\left[\theta \exp(\lambda_1) + (1 - \theta) \exp(\lambda_2)\right].
$$
The argument $\theta$ is a mixing probability while $\lambda_1$ and $\lambda_2$ are log densities or mass functions.
Finally we'll use [`poisson_log_lpmf()`](https://mc-stan.org/docs/functions-reference/poisson-distribution-log-parameterization.html). This is $\log \texttt{dpois}(y | \exp(\alpha))$, in other words the log of the Poisson pmf with the parameter on the *log scale*. We could alternatively have used `poisson_lpmf()` which is equivalent to $\log \texttt{dpois}(y | \lambda)$, i.e.\ working on the scale of $\lambda = \exp(\alpha)$ rather than $\alpha$, but I preferred to use the log scale to keep things directly comparable to the Poisson regression examples from above.

Now we're ready to look at my `.stan` file for the Poisson mixture model:
```{r}
m12_3_stan <- cmdstan_model('poisson-zero-inflated.stan')
m12_3_stan$print()
```
Everything should be fairly clear given the explanation from above. The only line that may need a bit of explanation is the one that includes `log_mix()`. Here I set the argument of `lambda_1` to `0`. This is because we can always write $p = 1 \times p = p \times \exp(\log(0))$. I also hard-code a `0` for the value of `y[i]` in `poisson_log_lpmf()` for the `if()` branch. Now let's test it out. Recall that the true parameter values were $\lambda = 1$ and $p = 0.2$ so the sampler is working well:
```{r}
dat <- list(N = length(y), y = y)
fit5 <- m12_3_stan$sample(
  data = dat,
  seed = 1234, 
  chains = 4,
  parallel_chains = 4,
  refresh = 500
)
fit5$summary() |> 
  knitr::kable(digits = 2)
```

## Normal-Poisson Mixture

Finally a model that *isn't* covered in *Statistical Rethinking*! For full details, along with discussion of my earlier implementation using `ulam()`, see `poisson-normal.qmd`. Here's the model, expressed in a non-centered parameterization:
$$
\begin{align*}
Y_i &\sim \text{Poisson}(\lambda_i)\\
\log(\lambda_i) &= \alpha + \beta X_i + \sigma U_i\\
U_i &\sim \text{Normal}(0, 1)\\
\alpha &\sim \text{Normal}(0, 1.5)\\
\beta &\sim \text{Normal}(0, 0.2)\\
\sigma &\sim \text{Exponential}(1)
\end{align*}
$$
These may not be the world's best priors for this setting, but they're inspired by examples from *Rethinking*. Here's some simulated data from the model with $\alpha = -2$, $\beta = 1$ and $\sigma = 1$:
```{r}
set.seed(298710)
n <- 1000
a <- -2
b <- 1
s <- 1

sim_dat <- tibble(x = runif(n, -3, 3),
                  u = rnorm(n, 0, s), 
                  y = rpois(n, exp(a + b * x)), 
                  ymix = rpois(n, exp(a + b * x + u)))

dat <- sim_dat |> 
  rowid_to_column('id') |>  # Add a row index for multilevel model index
  select(x, y = ymix, id)

rm(sim_dat)
```
And here's the STAN code generated by `ulam()`
```{r}
pois_mix <- ulam(
  alist(
    y ~ dpois(lambda),
    log(lambda) <- a + b * x + s * u[id],
    u[id] ~ dnorm(0, 1),
    a ~ dnorm(0, 1.5),
    b ~ dnorm(0, 0.2),
    s ~ dexp(1) 
  ), data = dat, sample = FALSE 
)
stancode(pois_mix)
```
This all looks fairly clear and clean, but building on what I've learned above I'll make a few improvements. Here's a link to the [STAN discussion board](https://discourse.mc-stan.org/t/normal-poisson-mixture-arm-15-1/32069?u=fditraglia) where I asked a question about fitting this model. The response contains some useful suggestions that I was able to follow up by querying ChatGPT and searching the STAN manual and language reference. Here's what I came up with:
```{r}
poisson_normal_mix <- cmdstan_model('poisson-normal-mixture.stan')
poisson_normal_mix$print()
```
My version is a bit simpler than the suggestion on the STAN message board and than the version generated by `ulam()`. I don't fully understand this feature yet, but STAN allows something called [affinely transformed reals](https://mc-stan.org/docs/reference-manual/scalar-data-types-and-variable-declarations.html#affinely-transformed-real) that can be used to implement re-centered parameterizations in a slightly different way. Most other examples of re-centered parameterizations used a `transformed parameters` block, whereas I did not. This is because we don't actually care about the values of the errors on the "true" scale. We're simply interested in the parameters $\alpha$, $\beta$, and $\sigma$ in this case. I also don't need the `id` column of `dat`. 

Let's see how it works. Recall that the true parameter values were $\alpha = -2$, $\beta = 1$ and $\sigma = 1$. Looks great! In fact it looks much better than when I fitted the same model using `ulam()`
```{r}
d <- list(N = nrow(dat), y = dat$y, x = dat$x)
fit6 <- poisson_normal_mix$sample(
  data = d, 
  seed = 1234, 
  chains = 4,
  parallel_chains = 4,
  refresh = 500
)
fit6$summary(variables = c('alpha', 'beta', 'sigma')) |> 
  knitr::kable(digits = 2) 
```



## Some notes / things to consider next

- Explain about [affinely transformed reals](https://mc-stan.org/docs/reference-manual/scalar-data-types-and-variable-declarations.html#affinely-transformed-real)
- Potentially try the model with a half-normal prior instead. Link to this reference on [prior choice](https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations) and also discuss how one merely needs to put a lower bound on the parameter `<lower = 0>` to get the half-normal. This is the flip side of something mentioned on pages 374-375 of *A Student's Guide to Bayesian Statistics*, namely that placing a uniform prior on parameter does *not* actually constrain the parameter to lie between zero and one. Remember that `~` is really just syntactic sugar for an update to `target` that represents the prior contribution to the unnormalized posterior. If you want a parameter with restricted range, you have to restrict it explicitly. 
- See what the Rhat looks like. The old recommendation was $<1.1$ means everything is ok, but I believe the new recommendation is $<1.01$. When I tried to fit this model using `ulam()` I think some of the Rhat values were a bit larger. 
- It might be worth posting my code and results on the discussion forum from above, both for my reference and to help others. I could also ask if anyone has tips for how to improve my program. A point worth emphasizing is that I was getting hung up on the (illusory) distinction between a mixture and a hierarchical model. I think it's because I was thinking about how you *must* integrate out discrete latent parameters in STAN. Of course the normal-Poisson mixture is continuous, so this doesn't apply.
- I need to learn more about non-centered parameterizations: [this is helpful](https://betanalpha.github.io/assets/case_studies/hierarchical_modeling.html#1_Modeling_Heterogeneity) and there's also an example on pages 432-439 of *A Student's Guide to Bayesian Statistics*. Here's the relevant entry from the [STAN manual](https://mc-stan.org/docs/stan-users-guide/reparameterization.html).
- I'm still a bit confused about why and when we need a Jacobian adjustment in STAN. Here are some resources: [densities](https://betanalpha.github.io/assets/case_studies/probability_theory.html#42_probability_density_functions), [Jacobians](https://jsocolar.github.io/jacobians/), [do I need a Jacobian adjustment here?](https://discourse.mc-stan.org/t/do-i-need-jacobian-adjustment-here/19875/14). I know that the Jacobian of an affine transformation is a constant, so this can be ignored. (It becomes an additive constant in the log posterior). Actually [perhaps this entry from the STAN manual](https://mc-stan.org/docs/stan-users-guide/changes-of-variables.html#change-of-variables-vs.-transformations) is the best thing to read. It distinguishes between a "change of variables" and a "variable transformation." The question is whether we transform *before or after* sampling. If we transform after sampling, no Jacobian adjustment is needed. 
- This is a very nice [sentence](https://betanalpha.github.io/assets/case_studies/probability_theory.html#42_probability_density_functions):

> Unlike probability mass functions, probability densities don’t transform quite as naturally under a measurable transformation. The complication is that the differential volumes over which we integrate will in general change under such a transformation, and probability density functions have to change in the opposite way to compensate and ensure that probabilities are conserved. 

